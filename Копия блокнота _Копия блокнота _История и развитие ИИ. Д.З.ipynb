{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y91MF1j8_RBwakmhyUwLXQOpk-6GwnRx","timestamp":1734968841344},{"file_id":"1hjBsWuHLjTDYiAtkly75yXTBGU6VQONJ","timestamp":1734967179294}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Домашнее задание"],"metadata":{"id":"RKVH7ZaAezCN"}},{"cell_type":"markdown","source":["## История и развитие искусственного интеллекта (ИИ)\n","\n","### Введение\n","\n","Искусственный интеллект (ИИ) — это область компьютерных наук, посвящённая созданию систем, способных выполнять задачи, которые требуют человеческого интеллекта. Сюда входят такие задачи, как распознавание речи, принятие решений, перевод текстов и распознавание изображений.\n","\n","### История развития ИИ\n","\n","1. **Ранние исследования (1950-е годы):**\n","   - **1950:** Алан Тьюринг предложил тест Тьюринга, как критерий для определения интеллекта машины.\n","   - **1956:** В Дартмуте состоялась первая конференция по ИИ, которая считается началом формального развития этой области.\n","\n","2. **Золотой век ИИ (1960-1970-е годы):**\n","   - В этот период были разработаны первые программы ИИ, такие как логические теоремы и системы, основанные на правилах.\n","   - **1966:** Проект ELIZA Джозефа Вейценбаума — первая программа, которая имитировала общение на естественном языке.\n","\n","3. **Зима ИИ (1970-1980-е годы):**\n","   - Период упадка интереса и финансирования в области ИИ, вызванный разочарованием в результатах исследований и ограничениями вычислительных мощностей.\n","\n","4. **Возрождение ИИ (1990-е годы):**\n","   - Возрождение интереса к ИИ благодаря успехам в области машинного обучения и увеличению вычислительных мощностей.\n","   - **1997:** Компьютер Deep Blue от IBM победил чемпиона мира по шахматам Гарри Каспарова.\n","\n","5. **Современный ИИ (2000-е годы — настоящее время):**\n","   - Бурное развитие глубокого обучения и нейронных сетей благодаря большим данным (Big Data) и мощным графическим процессорам (GPU).\n","   - **2012:** Прорыв в распознавании изображений с использованием сверточных нейронных сетей (CNN) в конкурсе ImageNet.\n","\n","### Однослойный и многослойный перцептрон\n","\n","Перцептрон — это простейшая форма искусственной нейронной сети, предложенная Фрэнком Розенблаттом в 1957 году. Перцептрон используется для задач классификации.\n","\n","#### Однослойный перцептрон\n","\n","Однослойный перцептрон состоит из одного слоя нейронов и может решать только линейно разделимые задачи.\n","\n","#### Пример кода однослойного перцептрона на Python\n"],"metadata":{"id":"g_DiXNsZd6xV"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Функция активации (шаговая функция)\n","def step_function(x):\n","    return np.where(x >= 0, 1, 0)\n","\n","class Perceptron:\n","    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n","        self.W = np.zeros(input_size + 1)\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","\n","    def predict(self, x):\n","        return step_function(np.dot(self.W, x))\n","\n","    def train(self, X, y):\n","        for _ in range(self.epochs):\n","            for xi, target in zip(X, y):\n","                xi = np.insert(xi, 0, 1)  # Вставка смещения (bias)\n","                prediction = self.predict(xi)\n","                self.W += self.learning_rate * (target - prediction) * xi\n","\n","# Данные для обучения (И, ИЛИ)\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([0, 0, 0, 1])  # Операция И (AND)\n","\n","perceptron = Perceptron(input_size=2)\n","perceptron.train(X, y)\n","\n","# Тестирование\n","for xi in X:\n","    xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n","    print(f\"{xi} -> {perceptron.predict(xi_with_bias)}\")\n"],"metadata":{"id":"tkmzaZNweCqa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734967276311,"user_tz":-180,"elapsed":1041,"user":{"displayName":"Жук Сергей Борисович","userId":"17355960566057784330"}},"outputId":"47237f86-c680-4a6f-ce65-c34644e32818"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0] -> 0\n","[0 1] -> 0\n","[1 0] -> 0\n","[1 1] -> 1\n"]}]},{"cell_type":"markdown","source":["#### Многослойный перцептрон (MLP)\n","\n","Многослойный перцептрон состоит из нескольких слоев нейронов и способен решать нелинейные задачи. Он включает входной слой, один или несколько скрытых слоев и выходной слой."],"metadata":{"id":"6M6YbJnldu4i"}},{"cell_type":"markdown","source":["#### Пример кода многослойного перцептрона на Python с использованием библиотеки `scikit-learn`"],"metadata":{"id":"7sCs1ZV6blAU"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","import numpy as np\n","\n","# Данные для обучения (И, ИЛИ)\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([0, 0, 0, 1])  # Операция И (AND)\n","\n","# Создание и обучение MLP-классификатора\n","mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=400, learning_rate_init=0.01, solver='adam')\n","mlp.fit(X, y)\n","\n","# Тестирование\n","for xi in X:\n","    print(f\"{xi} -> {mlp.predict([xi])[0]}\")"],"metadata":{"id":"Y4aS-x02cPp1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734967322835,"user_tz":-180,"elapsed":3977,"user":{"displayName":"Жук Сергей Борисович","userId":"17355960566057784330"}},"outputId":"47045ea4-6316-4e24-d454-7d4187314689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0] -> 0\n","[0 1] -> 0\n","[1 0] -> 0\n","[1 1] -> 1\n"]}]},{"cell_type":"markdown","source":["### Задание\n","\n","Многослойный перцептрон (MLP) может решать задачи, которые однослойный перцептрон не способен решить, из-за своей способности моделировать нелинейные зависимости. Одним из классических примеров такой задачи является проблема \"исключающее ИЛИ\" (XOR).\n","\n","### Проблема XOR\n","\n","Логическая операция XOR возвращает истину только в том случае, если один из входов истинный, а другой ложный. Ниже приведена таблица истинности для XOR:\n","\n","| Вход 1 | Вход 2 | XOR |\n","|--------|--------|-----|\n","|   0    |   0    |  0  |\n","|   0    |   1    |  1  |\n","|   1    |   0    |  1  |\n","|   1    |   1    |  0  |\n","\n","Эту задачу нельзя решить с помощью однослойного перцептрона, так как она не является линейно разделимой. Однако многослойный перцептрон, содержащий хотя бы один скрытый слой, способен решить эту задачу.\n","\n","\n","Ниже приведен код решения задачи XOR **многослойным** персептроном.\n","\n","Разберите ее самостоятельно.\n","\n","После чего создайте новую кодовую ячейку. Скопируйте в нее код **однослойного** персептрона и попытайтесь решить задачу на 10 000, 20 000, 50 000 эпохах.\n","\n","Создайте текстовую ячейку и напишите в ней свои выводы об однослойных и многослойных персептронах.\n","\n","Сохраните колаб и пришлите на него ссылку преподавателю.\n"],"metadata":{"id":"w6HGKktpbujp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DahpZ9PqbFEF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734967472736,"user_tz":-180,"elapsed":670,"user":{"displayName":"Жук Сергей Борисович","userId":"17355960566057784330"}},"outputId":"f83a2e40-67ea-4fe0-b448-c2ca66117c0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0] -> 0\n","[0 1] -> 1\n","[1 0] -> 1\n","[1 1] -> 1\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","import numpy as np\n","\n","# Данные для обучения (XOR)\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([0, 1, 1, 0])  # Операция XOR\n","\n","# Создание и обучение MLP-классификатора\n","mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=5000, solver='adam')\n","mlp.fit(X, y)\n","\n","# Тестирование\n","for xi in X:\n","    print(f\"{xi} -> {mlp.predict([xi])[0]}\")\n"]},{"cell_type":"code","source":["#Скопируйте в код однослойного персептрона и попытайтесь решить задачу XOR на 10 000, 20 000, 50 000 эпохах."],"metadata":{"id":"Du6zENjXkRvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Функция активации (шаговая функция)\n","def step_function(x):\n","    return np.where(x >= 0, 1, 0)\n","\n","class Perceptron:\n","    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n","        self.W = np.zeros(input_size + 1)\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","\n","    def predict(self, x):\n","        return step_function(np.dot(self.W, x))\n","\n","    def train(self, X, y):\n","        for _ in range(self.epochs):\n","            for xi, target in zip(X, y):\n","                xi = np.insert(xi, 0, 1)  # Вставка смещения (bias)\n","                prediction = self.predict(xi)\n","                self.W += self.learning_rate * (target - prediction) * xi\n","\n","# Данные для обучения (И, ИЛИ)\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([0, 0, 0, 1])  # Операция И (AND)\n","\n","#решить задачу XOR на 10 000, 20 000, 50 000 эпохах\n","perceptron = Perceptron(input_size=2, epochs=50000)\n","perceptron.train(X, y)\n","\n","# Тестирование\n","for xi in X:\n","    xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n","    print(f\"{xi} -> {perceptron.predict(xi_with_bias)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LyYeQvUH-F9","executionInfo":{"status":"ok","timestamp":1734968188684,"user_tz":-180,"elapsed":7489,"user":{"displayName":"Жук Сергей Борисович","userId":"17355960566057784330"}},"outputId":"6988a545-3719-4ae0-c5c4-fc11c25c30b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0] -> 0\n","[0 1] -> 0\n","[1 0] -> 0\n","[1 1] -> 1\n"]}]},{"cell_type":"markdown","source":["Персептрон – это базовая модель нейронной сети, которая была разработана в середине XX века для решения задач классификации и распознавания образов. Персептроны могут быть однослойными и многослойными, каждый из которых имеет свои особенности, преимущества и недостатки.\n","\n","Однослойный персептрон состоит из одного слоя весовых коэффициентов, который соединяет входные данные с выходным узлом. Он способен решать задачи линейного разделения данных.\n","Многослойный персептрон включает несколько слоев нейронов между входами и выходом. Каждый слой может выполнять нелинейную трансформацию данных, что позволяет модели обучаться сложным функциям и решать задачи нелинейного разделения классов.\n","\n","Заключение\n","\n","Однослойные и многослойные персептроны представляют собой разные подходы к решению задач машинного обучения.\n","Однослойные персептроны просты и эффективны для линейных задач. Многослойные персептроны обладают большей гибкостью и способностью решать сложные задачи, однако требуют больше времени и ресурсов для обучения и настройки.\n"],"metadata":{"id":"aopA6KgiK0sk"}}]}